{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Lesson3.2_SGD-LinearRegression.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GibJlqMyG83k"
      },
      "source": [
        "#hide\n",
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()\n",
        "\n",
        "#hide\n",
        "from fastbook import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RH9Q7iHrG84K"
      },
      "source": [
        "from fastai.vision.widgets import *\n",
        "from fastai.vision.all import *"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11ZNeJrHG84R"
      },
      "source": [
        "# Lesson 4 (suite): Gradient Descent with MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e58jsQI9qFuC"
      },
      "source": [
        "from torchvision.datasets import MNIST"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mvr3xx3xqJ4S"
      },
      "source": [
        "trainset = MNIST('../', download=True, train=True)\n",
        "testset = MNIST('../', download=True, train=False)"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzwTLVSPq6a4",
        "outputId": "a566194c-b715-4037-aef9-860011006964"
      },
      "source": [
        "trainset.data[0]  # looks like a five"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253, 253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253, 253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253, 205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,  90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253, 190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35, 241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221, 253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253, 253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253, 195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,  11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], dtype=torch.uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "mWXZKSuHragP",
        "outputId": "fbb0adc3-c834-4017-b25f-9d8725f9a200"
      },
      "source": [
        "plt.imshow(trainset.data[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7c12e0bf98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NbUWf_IrSON",
        "outputId": "60f83015-f0cd-4546-edec-9352d50b380e"
      },
      "source": [
        "y_train = trainset.targets\n",
        "y_test = testset.targets\n",
        "\n",
        "y_train[0]  # indeed, the label for the first image is a 5"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wBvM5ULs5D_",
        "outputId": "17588f31-0a99-4e6b-83f6-5d8d0cc99827"
      },
      "source": [
        "# 60 000 images for training, 10 000 for testing\n",
        "trainset.data.shape, testset.data.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([60000, 28, 28]), torch.Size([10000, 28, 28]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-DKK0SfsebP"
      },
      "source": [
        "# So we've got 60 000 square images of 28*28 pixels\n",
        "# Those square images are nice for plotting and seing what's in there, \n",
        "# but we can't pass them to a linear model\n",
        "# as seen in the lesson, use view or reshape to have all the pixels for an image in a single row \n",
        "\n",
        "train = trainset.data.reshape(60000, -1)\n",
        "test = testset.data.reshape(10000, -1)\n",
        "\n",
        "assert train.shape[1] == 784\n",
        "assert test.shape[1] == 784"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k900bSPUrXso",
        "outputId": "980d3ab2-8686-4e46-d8cb-eaa3631a759d"
      },
      "source": [
        "# FLoating point numbers work better with pytorch...\n",
        "train.dtype"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.uint8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tdl0IUQWui4X"
      },
      "source": [
        "# So we pass the data to float32 torch tensors\n",
        "train = train.to(torch.float32)\n",
        "test = test.to(torch.float32)"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83kL5VWoulbQ",
        "outputId": "e073c23b-3a3f-4020-e4da-c52ce1907f06"
      },
      "source": [
        "# The data isn't normalized\n",
        "# use the tensor method we've seen in the 3.1 notebook to print the mean and \n",
        "# standard deviation of the data to see by yourself...\n",
        "m, std = train.____(), train._____\n",
        "print(m.item(), std.item())\n",
        "\n",
        "assert m.item() == 33.31842041015625\n",
        "assert std.item() == 78.56748962402344"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "33.31842041015625 78.56748962402344\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhXTAo5mun77",
        "outputId": "179c00df-6101-4a7c-873f-15474de7fb96"
      },
      "source": [
        "# So we normalize it\n",
        "train = (train - m) / std\n",
        "test = __________________ # do the same for the test set\n",
        "print(train.mean(), train.std())  # 0 and 1, good"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.8892e-08) tensor(1.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdLgPvu4dljb"
      },
      "source": [
        "We used the trainset mean and standard deviation to normalize the test set. This is perfectly normal and it is what you shoud always do ! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FN5YZ8IIG84S"
      },
      "source": [
        "## Define a fully connected neural net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQfM5OPywgRk"
      },
      "source": [
        "def linear(x, neurons=50):\n",
        "    # x is a n by m matrix;\n",
        "    # to perform matrix operations, we want a 'm by neurons' matrix\n",
        "    m = x.shape[1]\n",
        "    w = torch.randn(m, neurons).requires_grad_()\n",
        "    b = torch.randn(neurons).requires_grad_()\n",
        "    return x @ w + b"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVUtaWouxQp8"
      },
      "source": [
        "def relu(x):\n",
        "    return x.clamp_min(0.)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_W2yl_ixTEk"
      },
      "source": [
        "def model(x):\n",
        "    x = linear(x, 50)\n",
        "    x = relu(x)\n",
        "    x = ______(x, 10)   # We want 10 outputs because we have 10 classes\n",
        "    return x "
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMc95FHuxZc-",
        "outputId": "26e3a951-9fdf-4cea-cf03-b1416915adba"
      },
      "source": [
        "print(\"All possible classes (the numbers from 0 to 9):\", y_train.unique())\n",
        "print(\"That's\", len(y_train.unique()), \"classes\")"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All possible classes (the numbers from 0 to 9): tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
            "That's 10 classes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N84Lud2Ax7dF",
        "outputId": "1cd3547b-a102-4fdd-8e16-545321a7698f"
      },
      "source": [
        "# input your train data into your model to get predictions...\n",
        "\n",
        "output = _____(_____)\n",
        "output.shape  # should be torch.Size([60000, 10]), 10 preds for each of the 60k imgs"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdWbJYxTyCrM"
      },
      "source": [
        "So our model outputs 10 numbers for each image in our dataset. You can think of those ten numbers as follow: \n",
        "\n",
        "\"For this image, what is the probability that it is a 0 ? a one ? a two ? ... a nine ?\" "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlQez7IvyXMo"
      },
      "source": [
        "But are those numbers real probabilities ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSChh1R2yaeR",
        "outputId": "71d00d14-1b3f-46d3-e04a-d4df25ecd494"
      },
      "source": [
        "output[0]"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 425.5692,  199.6936,   40.0095,  278.0396,   -3.7494,  144.4044, -231.4400,   -7.4895,   17.7265,  129.2715], grad_fn=<SelectBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmCAg1jWye35"
      },
      "source": [
        "Absolutely not: most are greater than one, some are negative, and their sum doesn't add to 1. We'll use a loss function that is called <b>cross-entropy</b>. We'll review in more details how Cross-Entropy works in a future notebook, but for now you just need a broad understanding of what it does.\n",
        "\n",
        "It does two thing:\n",
        "\n",
        "- transform those numbers into numbers that behave like probabilities (they will sum to 1, and none will be greater than 1 or inferior to 0).\n",
        "- out of these 10 probability, it picks the one that relates to the class your model should have predicted. If this number happens to be 1, great: you predicted 100% probability that is was the correct class. If it's less than that, you get a penalty."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWVw4oV20Fqo"
      },
      "source": [
        "## Forward pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OP4jdNHg0IHK",
        "outputId": "2ec31799-c60a-4207-9dc8-3fe488a57d00"
      },
      "source": [
        "output = model(train)\n",
        "loss = F.cross_entropy(output, y_train)\n",
        "loss"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(211.9291, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PB5ONsOF0OAw"
      },
      "source": [
        "## Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5JgUyjWZK2F"
      },
      "source": [
        "#Data and labels:\n",
        "INPUT = train\n",
        "TARGETS = y_train\n",
        "\n",
        "# parameters we can change:\n",
        "EPOCHS = 25\n",
        "LR = 0.5"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IKMA2Qf0TtA",
        "outputId": "cb621eb3-7b2c-4ef8-c4bb-5925d110a649"
      },
      "source": [
        "# Create layers for our model\n",
        "# help yourself with what we did in the above section\n",
        "layer1 = torch._____([784, 50]).requires______()\n",
        "activation = nn.ReLU()\n",
        "layer2 = _____._____([__, __]).______________()\n",
        "\n",
        "# Training loop\n",
        "for i in range(EPOCHS):\n",
        "    l1_output = activation(INPUT @ layer1)  # for code simplicity, we don't add the bias\n",
        "    model_output = l1_output @ layer2\n",
        "\n",
        "    loss = F.cross_entropy(____________, _______)\n",
        "    if i%5 == 0:\n",
        "        print(loss)\n",
        "    loss.________()\n",
        "    with torch.no_grad():\n",
        "        layer1 -= layer1.grad * LR\n",
        "        layer2 -= layer_.____ * __\n",
        "        layer1.grad.zero_()\n",
        "        layer2.____._____()"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(207.2033, grad_fn=<NllLossBackward>)\n",
            "tensor(4.4755, grad_fn=<NllLossBackward>)\n",
            "tensor(3.0572, grad_fn=<NllLossBackward>)\n",
            "tensor(2.7618, grad_fn=<NllLossBackward>)\n",
            "tensor(2.6250, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIMmog13WtSN"
      },
      "source": [
        "# Stochastic Gradient Descent\n",
        "\n",
        "Stochastic Gradient Descent is just a fancy name for doing what we did above, except that instead of making predictions on ** all ** the pictures before we do gradient descent, we just take a bunch of them (say, 64), make predictions, and update our parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YkABkllf0Ae"
      },
      "source": [
        "This is a good opportunity to work on your recall skills. Can you pull out the code out of your head without looking up ...? ;) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmurLOVtY3VY",
        "outputId": "6c587f49-a59c-45df-b51e-722ec2f8a15d"
      },
      "source": [
        "# Create layers for our model\n",
        "layer1 = ______________________________________\n",
        "activation = ____________\n",
        "layer2 = ______________________________________\n",
        "\n",
        "# Training loop\n",
        "for i in range(EPOCHS):\n",
        "    for img_index in range(0, 60000, 64):  # we iterate through the images, 64 imgs at a time\n",
        "        batch_of_sixtyfour_images = INPUT[img_index:img_index+64]\n",
        "\n",
        "        l1_output = activation(batch_of_sixtyfour_images @ ______)  \n",
        "        model_output = ___________________\n",
        "\n",
        "        loss = ______________________________________________________________\n",
        "        ______________\n",
        "        with torch.no_grad():\n",
        "            # update the parameters for layer1 and 2:\n",
        "\n",
        "\n",
        "            # don't let the gradients accumulate:\n",
        "\n",
        "\n",
        "    if i%5 == 0:\n",
        "        print(loss)"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.9681, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0626, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3562, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3047, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2205, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzN2tkwgY_ah"
      },
      "source": [
        "As you can see, the models performs better. That's because it has had many more opportunities to learn. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WzHg-0HbHfO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}